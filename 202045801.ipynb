{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터셋 출처: https://github.com/e9t/nsmc/\n",
    "- 영화 리뷰 데이터셋\n",
    "- 학습 데이터는 문자열 형태의 리뷰(review)와, 정답 라벨(rating)으로 구성.\n",
    "- 테스트 데이터는 라벨 없이 리뷰만을 담고 있습니다.\n",
    "- 학습 데이터와 테스트 데이터는 각각 약 15만개와 5만개로 랜덤하게 나누어 짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages (from konlpy) (1.5.1)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages (from konlpy) (5.3.0)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages (from konlpy) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (24.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "#토큰화에 사용할 라이브러리\n",
    "!pip install konlpy\n",
    "#진행도 시각화 라이브러리\n",
    "!pip install tqdm\n",
    "#머신러닝 알고리즘 라이브러리\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, random\n",
    "from tqdm import tqdm \n",
    "\n",
    "#재현 가능성을 위하여 랜덤 시드 고정\n",
    "seed=42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149993, 2)\n",
      "(49999, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"nsmc_train.csv\", index_col=0)\n",
    "test_data = pd.read_csv(\"nsmc_test.csv\", index_col=0)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146239 2\n",
      "(146239, 2)\n"
     ]
    }
   ],
   "source": [
    "print (train_data['review'].nunique(), train_data['rating'].nunique())\n",
    "train_data.drop_duplicates(subset=['review'], inplace=True)\n",
    "print (train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "군형잡힌 테스트 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rating  count\n",
      "0       0  73081\n",
      "1       1  73158\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['rating'].value_counts().plot(kind = 'bar')\n",
    "print(train_data.groupby('rating').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9324809</th>\n",
       "      <td>배우들의 인생연기가 돋보였던... 최고의 드라마</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9305425</th>\n",
       "      <td>아 혜리 보고싶다 ... 여군좀 ㅠ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239110</th>\n",
       "      <td>눈이 팅팅..... 정말 ,..... 대박이다......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9148159</th>\n",
       "      <td>캐슬린 터너의 보디는 볼만했다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144938</th>\n",
       "      <td>진짜 최고였다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  review  rating\n",
       "id                                              \n",
       "9324809       배우들의 인생연기가 돋보였던... 최고의 드라마       1\n",
       "9305425              아 혜리 보고싶다 ... 여군좀 ㅠ       0\n",
       "5239110  눈이 팅팅..... 정말 ,..... 대박이다......       1\n",
       "9148159                 캐슬린 터너의 보디는 볼만했다       0\n",
       "6144938                         진짜 최고였다.       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data 확인\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[\"review\"]\n",
    "y_train = np.array(train_data[\"rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "### 1.자연어 전처리\n",
    "> 텍스트 데이터 전처리를 위해 정규 표현식 적용.\n",
    "- 한글 문자, 영어 대문자, 영어 소문자, 띄어쓰기 이외의 문자를 제외.\n",
    "- 영어의 경우 같은 단어는 같은 토큰으로 분류하기 위해 대문자로 스케일링."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre-processing data: 100%|██████████| 146239/146239 [00:00<00:00, 638623.93it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = \"[^가-힣A-Za-z ]\"\n",
    "\n",
    "def apply_regex(pattern, text):         # 정규표현식을 이용한 필터링 적용\n",
    "    text = re.sub(pattern, \"\", text)    # 정규표현식 패턴에 맞는 값들을 텍스트에서 제거\n",
    "    text = text.upper()                 # 영어들을 찾아 대문자로 치환하는 코드 작성\n",
    "    return text\n",
    "\n",
    "x_train_preprocessed = [apply_regex(pattern, str(x[1])) \n",
    "                                    for x in tqdm(x_train.items(), \n",
    "                                    total=len(x_train), desc=\"pre-processing data\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['배우들의 인생연기가 돋보였던 최고의 드라마',\n",
       " '아 혜리 보고싶다  여군좀 ',\n",
       " '눈이 팅팅 정말  대박이다',\n",
       " '캐슬린 터너의 보디는 볼만했다',\n",
       " '진짜 최고였다',\n",
       " '오지호 연기 징챠 잘 한다  그리고 전효성 살인사건 빨리 풀었음 ',\n",
       " '너무 충격적이다그리고 최고다',\n",
       " '상실의 시대와 맞물려 창백하게 흘러가는 청춘의 공허함 리뷰참조하세요',\n",
       " '최고 ',\n",
       " '좀 하드하고 리얼한 액션만년악당이었던 이자웅에게는 잘 어울린다',\n",
       " '아 신이구나  깜짝놀랐네 헐',\n",
       " '너무 재밌고 감동  그루 츤데레 그리고 미니언들 너무너무너무귀엽다',\n",
       " '중국산 짝퉁 냄새가 풀풀 그나마 린즈링 때문에 참는다',\n",
       " '잔인하다 근데 그뿐이다 자꾸 코믹요소를 집어넣으려고 하는 의도가 보이는건 무었일까',\n",
       " '별로',\n",
       " '묘하다',\n",
       " '평점점은 양동근씨 소속사 사장님이신가요 ',\n",
       " '세실리아와 로비의 사랑이 너무 안타깝네요',\n",
       " '쓰레기 같은 영화 주제도 없도 이딴 영화 정말 싫다',\n",
       " '이상한 것 투성인 영화 허나 바로 그 점이 매력인']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_preprocessed[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. OKT를 이용한 Tokenization\n",
    "- 한국어 자연어 처리 라이브러리 konlpy의 OKT(Open Korean Text)를 사용\n",
    "- 문장 -> 단어 토큰화\n",
    "- 추가로 어근화 진행 \n",
    "> 참조: https://github.com/open-korean-text/open-korean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "def tokenize(sentence):\n",
    "    sentence_tokenized = okt.morphs(sentence, stem=True)\n",
    "    return sentence_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing data: 100%|██████████| 146239/146239 [02:59<00:00, 812.54it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['배우', '들', '의', '인생', '연기', '가', '돋보이다', '최고', '의', '드라마'],\n",
       " ['아', '혜리', '보다', '여군', '좀'],\n",
       " ['눈', '이', '팅팅', '정말', '대박', '이다'],\n",
       " ['캐슬', '린', '터너', '의', '보디', '는', '볼', '만', '하다'],\n",
       " ['진짜', '최고', '이다'],\n",
       " ['오지호', '연기', '징챠', '자다', '하다', '그리고', '전효성', '살인', '사건', '빨리', '풀다'],\n",
       " ['너무', '충격', '적', '이다', '그리고', '최고다'],\n",
       " ['상실',\n",
       "  '의',\n",
       "  '시대',\n",
       "  '와',\n",
       "  '맞다',\n",
       "  '물리다',\n",
       "  '창백하다',\n",
       "  '흘러가다',\n",
       "  '청춘',\n",
       "  '의',\n",
       "  '공허하다',\n",
       "  '리뷰',\n",
       "  '참조',\n",
       "  '하다'],\n",
       " ['최고'],\n",
       " ['좀',\n",
       "  '하드',\n",
       "  '하고',\n",
       "  '리얼',\n",
       "  '한',\n",
       "  '액션',\n",
       "  '만년',\n",
       "  '악당',\n",
       "  '이다',\n",
       "  '이자웅',\n",
       "  '에게는',\n",
       "  '자다',\n",
       "  '어울리다'],\n",
       " ['아', '신', '이구나', '깜짝', '놀라다', '헐다'],\n",
       " ['너무',\n",
       "  '재밌다',\n",
       "  '감동',\n",
       "  '그루',\n",
       "  '츤데레',\n",
       "  '그리고',\n",
       "  '미니',\n",
       "  '언',\n",
       "  '들',\n",
       "  '너무',\n",
       "  '너무',\n",
       "  '너무',\n",
       "  '귀엽다'],\n",
       " ['중국산', '짝퉁', '냄새', '가', '풀풀', '그나마', '린즈링', '때문', '에', '참다'],\n",
       " ['잔인하다',\n",
       "  '근데',\n",
       "  '그',\n",
       "  '뿐',\n",
       "  '이다',\n",
       "  '자꾸',\n",
       "  '코믹',\n",
       "  '요소',\n",
       "  '를',\n",
       "  '집어넣다',\n",
       "  '하다',\n",
       "  '의도',\n",
       "  '가',\n",
       "  '보이다',\n",
       "  '무었일까'],\n",
       " ['별로'],\n",
       " ['묘', '하다'],\n",
       " ['평점', '점', '은', '양동근', '씨', '소속사', '사장', '님', '이신', '가요'],\n",
       " ['세실리아', '와', '로비', '의', '사랑', '이', '너무', '안타깝다'],\n",
       " ['쓰레기', '같다', '영화', '주제', '도', '없다', '이딴', '영화', '정말', '싫다'],\n",
       " ['이상하다', '것', '투', '성인', '영화', '허다', '바로', '그', '점', '이', '매력', '인']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 구동 환경에 따라 5 ~ 15분 정도 소요\n",
    "x_train_tokenized = [tokenize(x) \n",
    "                     for x in tqdm(x_train_preprocessed, desc=\"tokenizing data\")]\n",
    "x_train_tokenized[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 불용어 제거\n",
    "- 리뷰의 긍정과 부정 여부를 판단하는데 필요없는 조사 등의 용어를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#의미가 없는 불용어 리스트\n",
    "stopwords = ['가', '걍', '과', '자', '잘', '들', '는', '도', '로', '를', '에', '와', '으로', '은', '이', '의', '자', '하다', '한']\n",
    "\n",
    "def exculde_stopwords(text):\n",
    "    result = [] #불용어가 제거된 텍스트\n",
    "    for word in text:\n",
    "        if word not in stopwords:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exclude stopwords data: 100%|██████████| 146239/146239 [00:00<00:00, 359242.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['배우', '인생', '연기', '돋보이다', '최고', '드라마'],\n",
       " ['아', '혜리', '보다', '여군', '좀'],\n",
       " ['눈', '팅팅', '정말', '대박', '이다'],\n",
       " ['캐슬', '린', '터너', '보디', '볼', '만'],\n",
       " ['진짜', '최고', '이다'],\n",
       " ['오지호', '연기', '징챠', '자다', '그리고', '전효성', '살인', '사건', '빨리', '풀다'],\n",
       " ['너무', '충격', '적', '이다', '그리고', '최고다'],\n",
       " ['상실', '시대', '맞다', '물리다', '창백하다', '흘러가다', '청춘', '공허하다', '리뷰', '참조'],\n",
       " ['최고'],\n",
       " ['좀', '하드', '하고', '리얼', '액션', '만년', '악당', '이다', '이자웅', '에게는', '자다', '어울리다'],\n",
       " ['아', '신', '이구나', '깜짝', '놀라다', '헐다'],\n",
       " ['너무', '재밌다', '감동', '그루', '츤데레', '그리고', '미니', '언', '너무', '너무', '너무', '귀엽다'],\n",
       " ['중국산', '짝퉁', '냄새', '풀풀', '그나마', '린즈링', '때문', '참다'],\n",
       " ['잔인하다', '근데', '그', '뿐', '이다', '자꾸', '코믹', '요소', '집어넣다', '의도', '보이다', '무었일까'],\n",
       " ['별로'],\n",
       " ['묘'],\n",
       " ['평점', '점', '양동근', '씨', '소속사', '사장', '님', '이신', '가요'],\n",
       " ['세실리아', '로비', '사랑', '너무', '안타깝다'],\n",
       " ['쓰레기', '같다', '영화', '주제', '없다', '이딴', '영화', '정말', '싫다'],\n",
       " ['이상하다', '것', '투', '성인', '영화', '허다', '바로', '그', '점', '매력', '인']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_stopwords_excluded = [exculde_stopwords(x) \n",
    "                              for x in tqdm(x_train_tokenized, desc=\"exclude stopwords data\")]\n",
    "x_train_stopwords_excluded[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 단어 임베딩\n",
    "- 토큰화와 불용어 필터를 거쳐 분리된 단어들에 대해 간단하게 one-hot encoding\n",
    "- 희소 표현법으로 볼 수 있음\n",
    "- *테스트 데이터에 대해서는 새로운 단어가 등장하면 값을 할당하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = dict()  # 단어 임베딩을 위한 딕셔너리\n",
    "embedding_value = 0\n",
    "\n",
    "def embed_tokens(sentence_tokenized, mode):\n",
    "    assert mode.upper() in [\"TRAIN\", \"TEST\"]\n",
    "    global embedding_value\n",
    "    \n",
    "    sentence_embedded = list()\n",
    "    for word in sentence_tokenized: \n",
    "        if mode.upper() == \"TRAIN\":\n",
    "            if word not in embedding_dict:\n",
    "                embedding_dict[word] = embedding_value\n",
    "                embedding_value += 1\n",
    "            sentence_embedded.append(embedding_dict[word])\n",
    "        elif mode.upper() == \"TEST\":\n",
    "            if word in embedding_dict:\n",
    "                sentence_embedded.append(embedding_dict[word])\n",
    "            else:\n",
    "                sentence_embedded.append(-1) \n",
    "    \n",
    "    return sentence_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding data: 100%|██████████| 146239/146239 [00:00<00:00, 257700.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21], [22, 4, 15]]\n",
      "total: 45361 words embedded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_embedded = [embed_tokens(x, mode=\"TRAIN\") \n",
    "                    for x in tqdm(x_train_stopwords_excluded, desc=\"embedding data\")]\n",
    "print(x_train_embedded[:5])\n",
    "print(\"total: %d words embedded.\"%(embedding_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 문장 벡터화\n",
    "- Bag of Words(BoW) 방법을 사용하여 모든 문장을 동일한 길이의 벡터로 스케일링\n",
    "- BoW는 어떤 단어들이 담긴 가방(집합)의 형태로 문장을 표현한다고 볼 수 있다.\n",
    "- 마치 가방 속에 든 물건의 개수를 세는 것처럼, 어떠한 문장을 고정된 m개의 단어들의 등장 횟수로 나타내는 방법이다.\n",
    "- 예를 들어, \"고양이는 귀엽고 강아지도 귀엽습니다.\"라는 문장은 다음과 같이 표현\n",
    "- {\"고양이\":1,\"귀엽\":2,\"고\":1,\"강아지\":1,\"는\":1,\"도\":1,\"습니다.\":1, \"인공지능\":0, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = embedding_value\n",
    "\n",
    "def to_BoW(x):\n",
    "    shape = (len (x), m)\n",
    "    x_BoW = np.zeros(shape) #배열 초기화\n",
    "    for i in tqdm(range(len(x)), desc=\"To BoW\"):\n",
    "        for index in x[i]:\n",
    "            x_BoW[i, index] += 1\n",
    "    return x_BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To BoW: 100%|██████████| 146239/146239 [00:00<00:00, 150255.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_BoW = to_BoW(x_train_embedded)\n",
    "x_train_BoW[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 차원 축소\n",
    "- 실제로 영화 리뷰에 쓰이는 단어를 추리기 위해서 데이터의 크기를 축소\n",
    "- 학습 데이터에서 50회 미만으로 등장한 단어는 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Bow Size:  (146239, 45361)\n",
      "After Dimension reduction:  (146239, 3115)\n"
     ]
    }
   ],
   "source": [
    "total_BoW = np.sum(x_train_BoW, axis=0)\n",
    "pieces = np.where(total_BoW >= 50)[0] # 50회 미만 단어 제거\n",
    "x_train_Dimension_reduction = x_train_BoW[:, pieces]\n",
    "print(\"Original Bow Size: \", x_train_BoW.shape)\n",
    "print(\"After Dimension reduction: \", x_train_Dimension_reduction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_rows = np.any(x_train_Dimension_reduction != 0, axis=1)\n",
    "x_train_Dimension_reduction_non_zero = x_train_Dimension_reduction[non_zero_rows]\n",
    "y_train_non_zero = y_train[non_zero_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류 수행\n",
    "모든 문장에 대하여 고정된 크기 m 차원의 벡터로 변환하였으니\n",
    "\n",
    "이를 바탕으로 알고리즘에 따른 분류 모델을 만들고, 정확도 비교 평가\n",
    "\n",
    "\n",
    "재현 가능성을 위해, 모든 모델의 랜덤시드는 42로 고정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre-processing data: 100%|██████████| 49999/49999 [00:00<00:00, 396606.81it/s]\n",
      "tokenizing data: 100%|██████████| 49999/49999 [01:27<00:00, 574.24it/s] \n",
      "embedding data: 100%|██████████| 49999/49999 [00:00<00:00, 373087.53it/s]\n",
      "To BoW: 100%|██████████| 49999/49999 [00:00<00:00, 156701.07it/s]\n"
     ]
    }
   ],
   "source": [
    "#TEST 데이터 전처리\n",
    "x_test = test_data[\"review\"]\n",
    "x_test_preprocessed = [apply_regex(pattern, str(x[1])) for x in tqdm(x_test.items(), total=len(x_test), desc=\"pre-processing data\")]\n",
    "x_test_tokenized = [tokenize(x) for x in tqdm(x_test_preprocessed, desc=\"tokenizing data\")]\n",
    "x_test_stopwords_excluded = [exculde_stopwords(x) for x in x_test_tokenized]\n",
    "x_test_embedded = [embed_tokens(x, mode=\"TEST\") for x in tqdm(x_test_stopwords_excluded, desc=\"embedding data\")]\n",
    "x_test_BoW = to_BoW(x_test_embedded)\n",
    "x_test_BoW_reduced = x_test_BoW[:, pieces] #차원 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 로지스틱 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8293577981651377\n",
      "Confusion Matrix:\n",
      "[[12049  2354]\n",
      " [ 2575 11907]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83     14403\n",
      "           1       0.83      0.82      0.83     14482\n",
      "\n",
      "    accuracy                           0.83     28885\n",
      "   macro avg       0.83      0.83      0.83     28885\n",
      "weighted avg       0.83      0.83      0.83     28885\n",
      "\n",
      "Training + Predicting Time: 853.6588 seconds\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀 분석\n",
    "#TEST 데이터에 대한 예측 수행 코드 작성\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_Dimension_reduction_non_zero, y_train_non_zero, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression(C=1, penalty=\"l2\", solver='saga', max_iter=500, random_state=42)\n",
    "start_time = time.time()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "y_val_pred = lr.predict(x_val)\n",
    "end_time = time.time()\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "class_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"Training + Predicting Time: {end_time - start_time:.4f} seconds\")\n",
    "yTestPred = lr.predict(x_test_BoW_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM, 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5369568980439675\n",
      "Confusion Matrix:\n",
      "[[ 2877 11526]\n",
      " [ 1849 12633]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.20      0.30     14403\n",
      "           1       0.52      0.87      0.65     14482\n",
      "\n",
      "    accuracy                           0.54     28885\n",
      "   macro avg       0.57      0.54      0.48     28885\n",
      "weighted avg       0.57      0.54      0.48     28885\n",
      "\n",
      "Training + Predicting Time: 155.8141 seconds\n"
     ]
    }
   ],
   "source": [
    "#서포트 벡터 머신\n",
    "#TEST 데이터에 대한 예측 수행 코드 작성\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_Dimension_reduction_non_zero, y_train_non_zero, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 서포트 벡터 머신 모델 정의 및 학습\n",
    "svm = SVC(kernel='linear', C=1.0, max_iter=500, random_state=42)\n",
    "start_time = time.time()\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "# Validation 데이터에 대한 예측\n",
    "y_val_pred = svm.predict(x_val)\n",
    "end_time = time.time()\n",
    "# 평가 지표 계산\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "class_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"Training + Predicting Time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Test 데이터에 대한 예측\n",
    "yTestPred = svm.predict(x_test_BoW_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 다층퍼셉트론, Neural Networks (MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8241647914142288\n",
      "Confusion Matrix:\n",
      "[[11977  2426]\n",
      " [ 2653 11829]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83     14403\n",
      "           1       0.83      0.82      0.82     14482\n",
      "\n",
      "    accuracy                           0.82     28885\n",
      "   macro avg       0.82      0.82      0.82     28885\n",
      "weighted avg       0.82      0.82      0.82     28885\n",
      "\n",
      "Training + Predicting Time: 615.1094 seconds\n"
     ]
    }
   ],
   "source": [
    "#다층퍼셉트론론\n",
    "#TEST 데이터에 대한 예측 수행 코드 작성\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_Dimension_reduction_non_zero, y_train_non_zero, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 다층퍼셉트론 모델 정의 및 학습\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "start_time = time.time()\n",
    "mlp.fit(x_train, y_train)\n",
    "\n",
    "# Validation 데이터에 대한 예측\n",
    "y_val_pred = mlp.predict(x_val)\n",
    "end_time = time.time()\n",
    "# 평가 지표 계산\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "class_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"Training + Predicting Time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Test 데이터에 대한 예측\n",
    "yTestPred = mlp.predict(x_test_BoW_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장 벡터화 심화 - TF-IDF 적용\n",
    "- BoW에서는 각 단어들의 중요도를 고려하지 않는다\n",
    "- 이를 보완하고자 TF-IDF를 적용해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#총 데이터 샘플의 수\n",
    "N = len(x_train_Dimension_reduction_non_zero)\n",
    "\n",
    "#어떤 단어가 등장하는 데이터 샘플의 수(DF)를 계산\n",
    "def calculate_document_frequency(x):\n",
    "    bool_arr = (x>0)\n",
    "    return bool_arr.sum(axis=0)\n",
    "\n",
    "#DF에 반비례하는 IDF 계산\n",
    "def calculate_inverse_document_frequency(document_frequency):\n",
    "    inverse_doc_freq = np.log(N / (document_frequency + 1))\n",
    "    return inverse_doc_freq\n",
    "\n",
    "document_frequency = calculate_document_frequency(x_train_Dimension_reduction_non_zero)\n",
    "inverse_document_frequency = calculate_inverse_document_frequency(document_frequency)\n",
    "\n",
    "#데이터에 IDF 값 적용\n",
    "x_train_TF_IDF = x_train_Dimension_reduction * inverse_document_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5523974381166695\n",
      "Confusion Matrix:\n",
      "[[ 3385 11018]\n",
      " [ 1911 12571]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.24      0.34     14403\n",
      "           1       0.53      0.87      0.66     14482\n",
      "\n",
      "    accuracy                           0.55     28885\n",
      "   macro avg       0.59      0.55      0.50     28885\n",
      "weighted avg       0.59      0.55      0.50     28885\n",
      "\n",
      "Training + Predicting Time: 159.9837 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import time\n",
    "\n",
    "# 데이터 분할\n",
    "x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    x_train_Dimension_reduction_non_zero, y_train_non_zero, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# TF-IDF 적용\n",
    "x_train_TF_IDF = x_train_split * inverse_document_frequency\n",
    "x_val_TF_IDF = x_val_split * inverse_document_frequency\n",
    "\n",
    "# 서포트 벡터 머신 모델 정의\n",
    "svm = SVC(kernel='linear', C=1.0, max_iter=500, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "start_time = time.time()\n",
    "svm.fit(x_train_TF_IDF, y_train_split)\n",
    "\n",
    "# Validation 데이터에 대한 예측\n",
    "y_val_pred = svm.predict(x_val_TF_IDF)\n",
    "end_time = time.time()\n",
    "\n",
    "# 평가 지표 계산\n",
    "accuracy = accuracy_score(y_val_split, y_val_pred)\n",
    "conf_matrix = confusion_matrix(y_val_split, y_val_pred)\n",
    "class_report = classification_report(y_val_split, y_val_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"Training + Predicting Time: {end_time - start_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class_weight='balanced'옵션을 통한 클래스 가중치 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kbg46\\anaconda3\\envs\\condatest\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5523974381166695\n",
      "Confusion Matrix:\n",
      "[[ 3385 11018]\n",
      " [ 1911 12571]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.24      0.34     14403\n",
      "           1       0.53      0.87      0.66     14482\n",
      "\n",
      "    accuracy                           0.55     28885\n",
      "   macro avg       0.59      0.55      0.50     28885\n",
      "weighted avg       0.59      0.55      0.50     28885\n",
      "\n",
      "Training + Predicting Time: 161.3268 seconds\n"
     ]
    }
   ],
   "source": [
    "# 서포트 벡터 머신 모델 정의\n",
    "svm = SVC(kernel='linear', C=1.0, max_iter=500, random_state=42, class_weight='balanced')\n",
    "\n",
    "# 모델 학습\n",
    "start_time = time.time()\n",
    "svm.fit(x_train_TF_IDF, y_train_split)\n",
    "\n",
    "# Validation 데이터에 대한 예측\n",
    "y_val_pred = svm.predict(x_val_TF_IDF)\n",
    "end_time = time.time()\n",
    "\n",
    "# 평가 지표 계산\n",
    "accuracy = accuracy_score(y_val_split, y_val_pred)\n",
    "conf_matrix = confusion_matrix(y_val_split, y_val_pred)\n",
    "class_report = classification_report(y_val_split, y_val_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"Training + Predicting Time: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터 최적화 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.1}\n",
      "Best Cross-validation Score:  0.8257486593460529\n",
      "Validation Accuracy: 0.8275575558248226\n",
      "Confusion Matrix:\n",
      "[[12032  2371]\n",
      " [ 2610 11872]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83     14403\n",
      "           1       0.83      0.82      0.83     14482\n",
      "\n",
      "    accuracy                           0.83     28885\n",
      "   macro avg       0.83      0.83      0.83     28885\n",
      "weighted avg       0.83      0.83      0.83     28885\n",
      "\n",
      "Training + Predicting Time: 34.7169 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grid = {'C': [0.1, 1, 10]}\n",
    "\n",
    "# GridSearchCV로 하이퍼파라미터 튜닝\n",
    "grid_search = GridSearchCV(LinearSVC(class_weight='balanced', random_state=42, max_iter=1000), param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "# 학습 시작 시간 기록\n",
    "start_time = time.time()\n",
    "grid_search.fit(x_train_TF_IDF, y_train_split)\n",
    "end_time = time.time()\n",
    "\n",
    "# 최적의 하이퍼파라미터와 정확도 출력\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Cross-validation Score: \", best_score)\n",
    "\n",
    "# 최적 모델로 예측 수행\n",
    "svm_best = grid_search.best_estimator_\n",
    "y_val_pred = svm_best.predict(x_val_TF_IDF)\n",
    "\n",
    "# 예측 결과 평가\n",
    "accuracy = accuracy_score(y_val_split, y_val_pred)\n",
    "conf_matrix = confusion_matrix(y_val_split, y_val_pred)\n",
    "class_report = classification_report(y_val_split, y_val_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# 학습 + 예측 시간 출력\n",
    "print(f\"Training + Predicting Time: {end_time - start_time:.4f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
